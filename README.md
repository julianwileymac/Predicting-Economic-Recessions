# Predicting Economic Recessions using Gold Prices and Macroeconmic Indicators

## 1. Intro and Motivation

Predicting economic recessions is one of the most important applications of machine learning for economics. Recessions are major events that have significant implications for all manner of economic policies and business decisions. Currently, making predictions about future economic conditions is done by economists using traditional statistical models. This approach is slow and subjective, as experts can disagree until well into the start of a recession. This project aims to use machine learning models to predict future economic conditions quickly so that policymakers and corporate actors can begin making plans to mitigate the consequences of these shifts as early as possible.

## 2. Data Prep
Our dataset consisted of a combination of macroeconomics indicators and gold commodities prices, obtained through the aforementioned software tools and libraries. It was cleaned with basic preprocessing steps. Gold prices came in standard OHLCV (open/high/low/close/volume) format and was of daily frequency. The following macroeconomic indicators were used: S&P500 for baseline performance , Consumer Price Index, Personal Consumption Expenditures, Unemployment Rate,  GDP , Inflation,  M2 Money Stock, Federal Funds Rate, Market Yield on U.S. Treasury Securities at 10-Year Constant Maturity Quoted on an Investment Basis, Smoothed US Recession Probabilities, NBER Recession, and Total nonfarm employment.

## 3. Models

The first models we used were LSTM’s that predicted the probability of a recession at any given time based on the last 60 days of data. As with every model, we trained univariate and multivariate versions. These all shared the same architectures, the only difference being the input shapes. They all had 5 layers with 4 LSTM layers and 1 dense layer, each with a dropout after it with a rate of 0.5. Surprisingly, the univariate LSTMs performed the best with the predicted recession probabilities very closely matching the actual probability when predictions were modeled on the test sets. This is antithetical to the results as judged by the root mean squared error in the training epochs, with the univariate LSTM having a RMSE of 0.0009809 and the multivariate LSTM having a RMSE of 0.00079603. Given the visible differences between the closeness of predictions on the test set, with the univariate more closely fitting to the actual predictions.
Next, we built GRUs, which are another form of time series specific models that have been shown to do well in forecasting. Again, we built out univariate and multivariate architectures, each with 5 layers. We added 4 GRU layers, each with 50 units, followed by a dropout layer for each. They performed quite well, but still failed to model the test set as accurately as the LSTMs.
The next model used variational autoencoders to try to map the inputs to our outputs with some lower dimensionality. These we tried to use because variational autoencoders have been shown to do well at pre4dicitng anomalies in time series. Given the relative sparsity of events in this data (there were only 2 recessions in the 15-year time span) this architecture was shown in an attempt to model it. The variational encoder consisted of 3 LSTM layers with 64 32 and 16 nodes, respectively. While the variational decoder also had 3 layers with 16 32 and 64 nodes, respectively. These models both performed very poorly with losses showing them to be very poor predictors. The univariate model had an RMSE of 0.0756 while the multivariate model had an RMSE of 0.00053676.
Lastly, we used CNN’s to predict our time series in an attempt to assess the performance of our other models against an architecture style that is not well suited for time series. Our CNN’s had different architectures and both required extensive adjustments to ensure the networks worked with our time series. The univariate model had 4 layers, a Conv1D layer with 20 nodes, kernel size of 4, and stride length of 4, 2 GRUs with 20 nodes each, a time-distributed dense output layer. The multivariate model was considerably deeper, having 10 layers. The first layer was a Conv1D layer with 128 nodes and a kernel size of 12, followed by a MaxPooling1D layer with a pool size of 2. Next Conv1D layer has 64 units and a kernel size of 3, followed by another MaxPooling1D layer with a pool size of 2. Last convolutional layer had 32 units and kernel size of 3 followed by the last MaxPooling1D layer that also has a pool size of 2. Next there are 2 GRUs with 16 nodes each, followed by a flatted layer and dropout at 0.1. Lastly the output layer is a one unit dense layer. The univariate model had an RMSE of 0.0758 while the multivariate model’s was 0.00025634.
